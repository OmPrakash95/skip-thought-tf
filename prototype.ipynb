{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%TODO\n",
    "* ~~add vocab_size feature to data_reader & vocab~~\n",
    "* ~~properly handle first and last messages in dialogs (they have only one target)~~\n",
    "* ~~next_seq decoder~~\n",
    "* ~~prev_seq decoder~~\n",
    "* ~~loss~~\n",
    "* ~~train op~~\n",
    "* ~~training+verbosing~~\n",
    "* many layers option\n",
    "* bidirectional option\n",
    "* saving/restoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow FLAGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('num_epochs', 100, \"Number of epochs.\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"The size of batch.\")\n",
    "tf.app.flags.DEFINE_integer('num_hidden', 512, 'Hidden size of GRU cell.')\n",
    "tf.app.flags.DEFINE_integer('embedding_size', 128, 'The size of word embeddings.')\n",
    "tf.app.flags.DEFINE_integer('max_vocab_size', 30, 'Size of vocabulary. Most frequent words are used.')\n",
    "tf.app.flags.DEFINE_integer('bottleneck_size', 128, 'Size of bottleneck softmax. It avoids matrices from num_hidden to vocab_size.')\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.02, \"Initial learning rate.\")\n",
    "tf.app.flags.DEFINE_float('decay_rate', 1.0, \"Exponential decay rate.\")\n",
    "tf.app.flags.DEFINE_float('grad_clip', 1500.0, \"Value for gradient clipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing. \n",
    "We read sequence data and generate `(prev, curr, next)` triples with sentences. They will be batched and passed to network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dr = data_reader.SequenceDataReader('data/chats1000.txt', max_vocab_size=FLAGS.max_vocab_size)\n",
    "\n",
    "# PAD_TOKEN_IDX = dr.vocab.encode_word(dr.vocab.PAD_TOKEN)\n",
    "# EOS_TOKEN_IDX = dr.vocab.encode_word(dr.vocab.EOS_TOKEN)\n",
    "# MAX_LENGTH = dr.max_len\n",
    "PAD_TOKEN_IDX = 0\n",
    "EOS_TOKEN_IDX = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_curr_prev_next_triples(origin_X):\n",
    "    line_lengths = map(len, origin_X)\n",
    "    empty_line_indices = list(map(lambda x: x[0], filter(lambda x: x[1] <= 1, enumerate(line_lengths))))\n",
    "    empty_line_indices = [-1]+empty_line_indices+[len(origin_X)]\n",
    "    triples = [] # (curr, prev, next)\n",
    "    for i in range(1, len(empty_line_indices)-1):\n",
    "        from_idx = empty_line_indices[i-1]+1\n",
    "        to_idx = empty_line_indices[i]\n",
    "        for k in range(from_idx+1, to_idx-1):\n",
    "            triples.append((origin_X[k], origin_X[k-1], origin_X[k+1]))\n",
    "    return list(zip(*triples)) # three lists with equal lengths, corresponding to curr, prev and next sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define placeholders and function for filling feed dictionary.\n",
    "\n",
    "Because all `*_decoder` functions in `tf.nn.seq2seq` take lists as inputs, we can't do the same thing for supporting variable-length sequences as we do for encoder (`input_placeholder`).\n",
    "\n",
    "To manage this problem, we could use bucketing (`tf.nn.seq2seq.model_with_buckets`) or just calculate maximum length of line in dataset and create such number of placeholders for decoder. \n",
    "\n",
    "`SequenceDataReader` has `max_length` property for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Encoder input\n",
    "input_placeholder = tf.placeholder(tf.int32, shape=[None,None], name='enc_inputs')\n",
    "sequence_length_placeholder = tf.placeholder(tf.int32, shape=[None,], name='seq_lengths')\n",
    "\n",
    "\n",
    "# 3. Correct next output sequence for next_seq decoder.\n",
    "next_seq_output_placeholder = [tf.placeholder(tf.int32, shape=[None,],\n",
    "                                              name='dec_next_seq_output{0}'.format(i)) for i in range(MAX_LENGTH)]\n",
    "\n",
    "\n",
    "# 4. Input for next_seq decoder. It contains last token in inputs (which is always <eos> token) and shifted decoder outputs.\n",
    "next_seq_input_placeholder = [tf.ones_like(next_seq_output_placeholder[0])*EOS_TOKEN_IDX] + next_seq_output_placeholder[1:]\n",
    "\n",
    "\n",
    "\n",
    "# 5. Correct previous output sequence for prev_seq decoder.\n",
    "prev_seq_output_placeholder = [tf.placeholder(tf.int32, shape=[None,],\n",
    "                                              name='dec_prev_seq_output{0}'.format(i)) for i in range(MAX_LENGTH)]\n",
    "\n",
    "\n",
    "# 6. Input for prev_seq decoder.\n",
    "prev_seq_input_placeholder = [tf.ones_like(prev_seq_output_placeholder[0])*EOS_TOKEN_IDX] + prev_seq_output_placeholder[1:]\n",
    "\n",
    "\n",
    "\n",
    "# 7. Seq loss weights\n",
    "prev_seq_loss_weights = [tf.placeholder(tf.float32, shape=[None,], name=\"prev_weight{0}\".format(i)) for i in range(MAX_LENGTH)]\n",
    "next_seq_loss_weights = [tf.placeholder(tf.float32, shape=[None,], name=\"next_weight{0}\".format(i)) for i in range(MAX_LENGTH)]\n",
    "\n",
    "def fill_feed_dict(curr_input, prev_output, next_output):\n",
    "    feed_dict = {\n",
    "        input_placeholder: curr_input,\n",
    "        sequence_length_placeholder: utils.padded_sequence_lengths(curr_input, pad_value=PAD_TOKEN_IDX),\n",
    "    }\n",
    "    feed_dict.update({next_seq_output_placeholder[i]: next_output[:,i] for i in range(next_output.shape[1])})\n",
    "    feed_dict.update({prev_seq_output_placeholder[i]: prev_output[:,i] for i in range(prev_output.shape[1])})\n",
    "    \n",
    "    prev_weights = utils.get_weights_for_sequence_loss(prev_output, PAD_TOKEN_IDX)\n",
    "    next_weights = utils.get_weights_for_sequence_loss(next_output, PAD_TOKEN_IDX)\n",
    "    feed_dict.update({prev_seq_loss_weights[i]: prev_weights[i] for i in range(len(prev_weights))})\n",
    "    feed_dict.update({next_seq_loss_weights[i]: next_weights[i] for i in range(len(next_weights))})\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define matrix for word embeddings.\n",
    "* Tensor `embedded` is used as `inputs` in encoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('embeddings'):\n",
    "    # Default initializer for embeddings should have variance=1.\n",
    "    sqrt3 = math.sqrt(3)  # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "    initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "    embedding_matrix = tf.get_variable(\"embedding_matrix\", shape=[FLAGS.max_vocab_size, FLAGS.embedding_size], initializer=initializer)\n",
    "\n",
    "embedded = tf.nn.embedding_lookup(embedding_matrix, input_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define encoder rnn.\n",
    "* Tensor `encoder_state` will be used as initial state in decoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('encoder'):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(FLAGS.num_hidden)\n",
    "    _, encoder_state = tf.nn.dynamic_rnn(cell,\n",
    "                                         dtype=tf.float32,\n",
    "                                         inputs=embedded,\n",
    "                                         sequence_length=sequence_length_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define two decoders. One for decoding previous sentence, and second for next sequence.\n",
    "\n",
    "* Instead of using `OutputProjectionWrapper` we could initialize output projection explicitly and pass it to `tf.nn.seq2seq._extract_argmax_and_embed`.\n",
    "\n",
    "\n",
    "* Also, we can't use `EmbeddingWrapper` because we want to share embeddings between encoder and decoders.\n",
    "\n",
    "\n",
    "* **NOTE** that we actually create two output variables for each decoder. One for training (without feeding previous output from decoder to the next input) and the second one for predicting. So, `next/prev_seq_outputs_predict` will not be used while training the model. They are only needed for predicting sequences when model is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define next sequence decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loop_function_train = tf.nn.seq2seq._extract_argmax_and_embed(embedding_matrix, update_embedding=True)\n",
    "# loop_function_predict = tf.nn.seq2seq._extract_argmax_and_embed(embedding_matrix, update_embedding=False)\n",
    "\n",
    "with tf.variable_scope(\"next_seq_decoder\"):\n",
    "    embedded_next_seq_inputs = [tf.nn.embedding_lookup(embedding_matrix, inp) for inp in next_seq_input_placeholder]\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.GRUCell(FLAGS.num_hidden)\n",
    "    cell = tf.nn.rnn_cell.OutputProjectionWrapper(cell, FLAGS.max_vocab_size)\n",
    "    \n",
    "    next_seq_outputs_train, _ = tf.nn.seq2seq.rnn_decoder(embedded_next_seq_inputs, initial_state=encoder_state,\n",
    "                                                          cell=cell, loop_function=loop_function_train)\n",
    "# with tf.variable_scope(\"next_seq_decoder\", reuse=True):\n",
    "#     next_seq_outputs_predict, _ = tf.nn.seq2seq.rnn_decoder(embedded_next_seq_inputs, initial_state=encoder_state,\n",
    "#                                                            cell=cell, loop_function=loop_function_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same thing with prev sequence decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"prev_seq_decoder\"):\n",
    "    embedded_prev_seq_inputs = [tf.nn.embedding_lookup(embedding_matrix, inp) for inp in prev_seq_input_placeholder]\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.GRUCell(FLAGS.num_hidden)\n",
    "    cell = tf.nn.rnn_cell.OutputProjectionWrapper(cell, FLAGS.max_vocab_size)\n",
    "    \n",
    "    prev_seq_outputs_train, _ = tf.nn.seq2seq.rnn_decoder(embedded_prev_seq_inputs, initial_state=encoder_state,\n",
    "                                                          cell=cell, loop_function=loop_function_train)\n",
    "# with tf.variable_scope(\"prev_seq_decoder\", reuse=True):\n",
    "#     prev_seq_outputs_predict, _ = tf.nn.seq2seq.rnn_decoder(embedded_prev_seq_inputs, initial_state=encoder_state,\n",
    "#                                                            cell=cell, loop_function=loop_function_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can define loss and train_op for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_prev = tf.nn.seq2seq.sequence_loss(prev_seq_outputs_train,\n",
    "                                        prev_seq_output_placeholder,\n",
    "                                        prev_seq_loss_weights)\n",
    "loss_next = tf.nn.seq2seq.sequence_loss(next_seq_outputs_train,\n",
    "                                        next_seq_output_placeholder,\n",
    "                                        next_seq_loss_weights)\n",
    "\n",
    "# Final loss.\n",
    "loss = loss_prev + loss_next\n",
    "\n",
    "# Optimizer with decaying learning rate.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(FLAGS.learning_rate,\n",
    "                                           global_step,\n",
    "                                           len(dr.get_data()),\n",
    "                                           FLAGS.decay_rate,\n",
    "                                           staircase=True)\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate)\n",
    "\n",
    "# Perform gradient clipping.\n",
    "tvars = tf.trainable_variables()\n",
    "grads = tf.gradients(loss, tvars)\n",
    "clipped_grads, norm = tf.clip_by_global_norm(tvars, FLAGS.grad_clip)\n",
    "\n",
    "train_op = opt.apply_gradients(zip(clipped_grads, tvars), global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the parameters in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings/embedding_matrix:0\n",
      "encoder/RNN/GRUCell/Gates/Linear/Matrix:0\n",
      "encoder/RNN/GRUCell/Gates/Linear/Bias:0\n",
      "encoder/RNN/GRUCell/Candidate/Linear/Matrix:0\n",
      "encoder/RNN/GRUCell/Candidate/Linear/Bias:0\n",
      "next_seq_decoder/rnn_decoder/GRUCell/Gates/Linear/Matrix:0\n",
      "next_seq_decoder/rnn_decoder/GRUCell/Gates/Linear/Bias:0\n",
      "next_seq_decoder/rnn_decoder/GRUCell/Candidate/Linear/Matrix:0\n",
      "next_seq_decoder/rnn_decoder/GRUCell/Candidate/Linear/Bias:0\n",
      "next_seq_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Matrix:0\n",
      "next_seq_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias:0\n",
      "prev_seq_decoder/rnn_decoder/GRUCell/Gates/Linear/Matrix:0\n",
      "prev_seq_decoder/rnn_decoder/GRUCell/Gates/Linear/Bias:0\n",
      "prev_seq_decoder/rnn_decoder/GRUCell/Candidate/Linear/Matrix:0\n",
      "prev_seq_decoder/rnn_decoder/GRUCell/Candidate/Linear/Bias:0\n",
      "prev_seq_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Matrix:0\n",
      "prev_seq_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias:0\n"
     ]
    }
   ],
   "source": [
    "for x in tvars:\n",
    "    print(x.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN_IDX, PAD_TOKEN_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norms = []\n",
    "bbb = None\n",
    "fff = {}\n",
    "ppp = None\n",
    "nnn = None\n",
    "def train(sess, verbose=1000):\n",
    "#     curr_data, prev_data, next_data = get_curr_prev_next_triples(dr.get_data())\n",
    "    curr_data = [list(np.random.randint(3, 20, size=10))+[EOS_TOKEN_IDX]]*1000\n",
    "    prev_data = [x[:-1:2]+[EOS_TOKEN_IDX] for x in curr_data]\n",
    "    next_data = [x[1:-1:2]+[EOS_TOKEN_IDX] for x in curr_data]\n",
    "    for e in range(FLAGS.num_epochs):\n",
    "        it = utils.seq2seq_triples_data_iterator(curr_data, prev_data, next_data, 10,\n",
    "                                                 batch_size=FLAGS.batch_size, shuffle=True, pad_value=PAD_TOKEN_IDX)\n",
    "        num_batches = int(np.ceil(len(curr_data)) / float(FLAGS.batch_size))\n",
    "        for b, (curr_batch, prev_batch, next_batch) in enumerate(it):\n",
    "            global bbb, fff, ppp, nnn\n",
    "            bbb = (curr_batch, prev_batch, next_batch)\n",
    "            start_time = time.time()\n",
    "            feed_dict = fill_feed_dict(curr_batch, prev_batch, next_batch)\n",
    "            fff = feed_dict\n",
    "            batch_loss, grad_norm, prev_pred, next_pred, _ = sess.run([loss, norm,\n",
    "                                                                       prev_seq_outputs_train,\n",
    "                                                                       next_seq_outputs_train,\n",
    "                                                                       train_op], feed_dict=feed_dict)\n",
    "            ppp = prev_pred\n",
    "            nnn = next_pred\n",
    "            norms.append(grad_norm)\n",
    "            batch_perplexity = math.exp(float(batch_loss)) if batch_loss < 300 else float(\"inf\")\n",
    "            end_time = time.time()\n",
    "            if b % verbose == 0:\n",
    "                    print(\n",
    "                        \"{}/{} (epoch {}), train_loss = {:.3f}, perplexity = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                        .format(e * num_batches + b,\n",
    "                                FLAGS.num_epochs * num_batches,\n",
    "                                e, batch_loss, batch_perplexity, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1500 (epoch 0), train_loss = 6.995, perplexity = 1091.262, time/batch = 0.218\n",
      "10/1500 (epoch 0), train_loss = 6.882, perplexity = 974.943, time/batch = 0.194\n",
      "15/1500 (epoch 1), train_loss = 6.846, perplexity = 939.839, time/batch = 0.177\n",
      "25/1500 (epoch 1), train_loss = 6.815, perplexity = 911.268, time/batch = 0.191\n",
      "30/1500 (epoch 2), train_loss = 6.805, perplexity = 902.771, time/batch = 0.173\n",
      "40/1500 (epoch 2), train_loss = 6.802, perplexity = 900.080, time/batch = 0.241\n",
      "45/1500 (epoch 3), train_loss = 6.802, perplexity = 900.004, time/batch = 0.178\n",
      "55/1500 (epoch 3), train_loss = 6.802, perplexity = 900.001, time/batch = 0.169\n",
      "60/1500 (epoch 4), train_loss = 6.802, perplexity = 900.001, time/batch = 0.186\n",
      "70/1500 (epoch 4), train_loss = 6.802, perplexity = 900.001, time/batch = 0.216\n",
      "75/1500 (epoch 5), train_loss = 6.802, perplexity = 900.001, time/batch = 0.180\n",
      "85/1500 (epoch 5), train_loss = 6.802, perplexity = 900.001, time/batch = 0.170\n",
      "90/1500 (epoch 6), train_loss = 6.802, perplexity = 900.001, time/batch = 0.254\n",
      "100/1500 (epoch 6), train_loss = 6.802, perplexity = 900.001, time/batch = 0.224\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b7f7730393e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f7592042fc8b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                                        \u001b[0mprev_seq_outputs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                                        \u001b[0mnext_seq_outputs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                                                        train_op], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mppp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mnnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dmitry/me/anaconda/envs/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dmitry/me/anaconda/envs/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dmitry/me/anaconda/envs/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/dmitry/me/anaconda/envs/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dmitry/me/anaconda/envs/venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    train(sess, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'dec_next_seq_output0:0' shape=(?,) dtype=int32>,\n",
       "  array([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output1:0' shape=(?,) dtype=int32>,\n",
       "  array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output2:0' shape=(?,) dtype=int32>,\n",
       "  array([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output3:0' shape=(?,) dtype=int32>,\n",
       "  array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "         9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output4:0' shape=(?,) dtype=int32>,\n",
       "  array([18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output5:0' shape=(?,) dtype=int32>,\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output6:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output7:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output8:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_next_seq_output9:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output0:0' shape=(?,) dtype=int32>,\n",
       "  array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output1:0' shape=(?,) dtype=int32>,\n",
       "  array([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output2:0' shape=(?,) dtype=int32>,\n",
       "  array([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output3:0' shape=(?,) dtype=int32>,\n",
       "  array([17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output4:0' shape=(?,) dtype=int32>,\n",
       "  array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output5:0' shape=(?,) dtype=int32>,\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output6:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output7:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output8:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'dec_prev_seq_output9:0' shape=(?,) dtype=int32>,\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)),\n",
       " (<tf.Tensor 'enc_inputs:0' shape=(?, ?) dtype=int32>,\n",
       "  array([[10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1],\n",
       "         [10, 12, 12,  9, 12, 14, 17,  9,  3, 18,  1]], dtype=int32)),\n",
       " (<tf.Tensor 'next_weight0:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight1:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight2:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight3:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight4:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight5:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight6:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight7:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight8:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'next_weight9:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight0:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight1:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight2:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight3:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight4:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight5:0' shape=(?,) dtype=float32>,\n",
       "  array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight6:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight7:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight8:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'prev_weight9:0' shape=(?,) dtype=float32>,\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)),\n",
       " (<tf.Tensor 'seq_lengths:0' shape=(?,) dtype=int32>,\n",
       "  array([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(fff.items(), key=lambda x: x[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0],\n",
       "       [10, 12, 12, 17,  3,  1,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n",
      "8\n",
      "21\n",
      "21\n",
      "25\n",
      "21\n",
      "21\n",
      "25\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(ppp)):\n",
    "    print(np.argmax(ppp[x], axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e73cf60>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bb630f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11cfc1780>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTvpmZjnipG9mliNO+mZmOeKkb2aWI/8f7e59Zryp+9YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c6f5c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0485924740ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [venv3]",
   "language": "python",
   "name": "Python [venv3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
